{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "Lec_Version_of_Assignment_4_3_1_A_Copy of LS_DS_431_RNN_and_LSTM_Assignment_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRdvvFuORxFA",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "GC9c3HK2RxFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "-kI_OcQbRxFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "Ep3sX8h2RxFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ac6a642d-2c55-42a7-9cb5-b253081d4c94"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALL’S WELL THAT ENDS WELL</td>\n",
              "      <td>2777</td>\n",
              "      <td>7738</td>\n",
              "      <td>ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>7739</td>\n",
              "      <td>11840</td>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>11841</td>\n",
              "      <td>14631</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>14632</td>\n",
              "      <td>17832</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>17833</td>\n",
              "      <td>27806</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0            ALL’S WELL THAT ENDS WELL  ...  ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...\n",
              "1  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...  THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...\n",
              "2                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...\n",
              "3                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "4            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ8StjJ1S7bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_k_words = 10000\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k_words,\n",
        "                                                  oov_token=\"<unk>\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jI7SgZeTLHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "c34a1643-29fb-4fa3-80e8-8a6f9176fe2e"
      },
      "source": [
        "sequences = []\n",
        "maxlen = 350 #> later cranked up to 350 from orig val of 101 (pre-modelfit)\n",
        "\n",
        "def split_text(text):\n",
        "\n",
        "  for i in range(0, len(text), maxlen):\n",
        "    seq = text[i:i+maxlen]\n",
        "    sequences.append(seq)\n",
        "\n",
        "df_toc['text'].apply(split_text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "5     None\n",
              "6     None\n",
              "7     None\n",
              "8     None\n",
              "9     None\n",
              "10    None\n",
              "11    None\n",
              "12    None\n",
              "13    None\n",
              "14    None\n",
              "15    None\n",
              "16    None\n",
              "17    None\n",
              "18    None\n",
              "19    None\n",
              "20    None\n",
              "21    None\n",
              "22    None\n",
              "23    None\n",
              "24    None\n",
              "25    None\n",
              "26    None\n",
              "27    None\n",
              "28    None\n",
              "29    None\n",
              "30    None\n",
              "31    None\n",
              "32    None\n",
              "33    None\n",
              "34    None\n",
              "35    None\n",
              "36    None\n",
              "37    None\n",
              "38    None\n",
              "39    None\n",
              "40    None\n",
              "41    None\n",
              "42    None\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NztZBYgTTu6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c3be0b73-68a6-4802-c0d5-d6f6139e089a"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nContents\\r\\n\\r\\nACT I\\r\\nScene I. Rossillon. A room in the Countess’s pala'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix6Xra-GTzZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b55bb3f-b0e2-4178-bfc0-3d0ddc2a56ab"
      },
      "source": [
        "len(sequences)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55819"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bv3aajUT2Mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3953a430-5ae8-4bc9-fdc1-fef6728359f3"
      },
      "source": [
        "len(sequences[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkE_Ft9sT42F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6340faf6-b6de-4996-ab9e-e5fea0ce72c5"
      },
      "source": [
        "len(sequences[-1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwT8duteT6x_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Now need to learn the vocab\n",
        "\n",
        "tokenizer.fit_on_texts(sequences)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b3X2YYrUEHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seqs = tokenizer.texts_to_sequences(sequences)\n",
        "# Produces integer encoding"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "522tNjWtUPY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8275259d-9737-4ddf-a55b-d839e4cfefaa"
      },
      "source": [
        "train_seqs[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3375,\n",
              " 64,\n",
              " 12,\n",
              " 1991,\n",
              " 1666,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3722,\n",
              " 2,\n",
              " 259,\n",
              " 282,\n",
              " 109,\n",
              " 5,\n",
              " 2780,\n",
              " 8,\n",
              " 417,\n",
              " 11,\n",
              " 3,\n",
              " 5274,\n",
              " 7960]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItQapSbqUgIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35e746d5-8527-45df-be23-ba704cc2ab97"
      },
      "source": [
        "len(train_seqs) == len(sequences)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyYzjQ5QVdAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add step to resolve IndexError - Filter out Empty Sequences\n",
        "\n",
        "train_seqs = [x for x in train_seqs if len(x) >= 2] #> so list is always 2 chars long"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr1xXHEqU4Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Will try and predicted word sequences as opposed to characters\n",
        "\n",
        "target = [x[-1] for x in train_seqs]\n",
        "\n",
        "train_seqs = [x[:-1] for x in train_seqs]\n",
        "\n",
        "# IndexError: list index out of range >>> got this error, last item probably \n",
        "# blank"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbGsD5q2X2Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# turn into tensors\n",
        "x = tf.convert_to_tensor(train_seqs, dtype=tf.int16)\n",
        "y = tf.convert_to_tensor(target, dtype=tf.int16)\n",
        "\n",
        "# Got error >> ValueError: Can't convert non-rectangular Python sequence to Tensor.\n",
        "\n",
        "# Error was from the different sequences being different shapes/lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKAZeh0vYX5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Correction is to pad the data to get seqs all same length,\n",
        "# and turn them into tensors, which are basically tf versions of np arrays\n",
        "# Set maxlen to 50 here so all seqs have length of 50\n",
        "\n",
        "# turn into tensors\n",
        "train_seqs = tf.keras.preprocessing.sequence.pad_sequences(train_seqs,\n",
        "                                                           maxlen=50,\n",
        "                                                           dtype='int32',\n",
        "                                                           padding='pre')\n",
        "x = tf.convert_to_tensor(train_seqs, dtype=tf.int16)\n",
        "y = tf.convert_to_tensor(target, dtype=tf.int16)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrGfdDNUYlGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f7dd315-ce96-4e1e-c9e0-9f16110ae744"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([55818, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRR0eiQ-V5Ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6d5cd424-896a-4a6f-8eb2-35fcb902f7a1"
      },
      "source": [
        "### Now have a vocab and transformed sequences, next step is to build out model\n",
        "\n",
        "embedding_dim = 256\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Embedding(10_000, embedding_dim), #> 10_000 words in vocab\n",
        "     tf.keras.layers.LSTM(128),\n",
        "     tf.keras.layers.Dense(10_000, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 256)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10000)             1290000   \n",
            "=================================================================\n",
            "Total params: 4,047,120\n",
            "Trainable params: 4,047,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMEMhbRDXCYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ijR-OdqXNlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fb5ace9-133f-48e8-9f6a-c80ff39e218f"
      },
      "source": [
        "model.fit(x, y,\n",
        "          validation_split=.15,\n",
        "          epochs=50,\n",
        "          batch_size=64)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "742/742 [==============================] - 33s 45ms/step - loss: 6.1066 - acc: 0.1433 - val_loss: 6.0163 - val_acc: 0.1507\n",
            "Epoch 2/50\n",
            "742/742 [==============================] - 33s 45ms/step - loss: 5.7477 - acc: 0.1657 - val_loss: 6.0215 - val_acc: 0.1525\n",
            "Epoch 3/50\n",
            "742/742 [==============================] - 30s 40ms/step - loss: 5.6050 - acc: 0.1746 - val_loss: 6.0301 - val_acc: 0.1556\n",
            "Epoch 4/50\n",
            "742/742 [==============================] - 28s 38ms/step - loss: 5.4578 - acc: 0.1808 - val_loss: 6.0676 - val_acc: 0.1586\n",
            "Epoch 5/50\n",
            "742/742 [==============================] - 32s 43ms/step - loss: 5.3200 - acc: 0.1843 - val_loss: 6.1368 - val_acc: 0.1588\n",
            "Epoch 6/50\n",
            "742/742 [==============================] - 30s 40ms/step - loss: 5.1960 - acc: 0.1880 - val_loss: 6.1963 - val_acc: 0.1610\n",
            "Epoch 7/50\n",
            "742/742 [==============================] - 29s 40ms/step - loss: 5.0770 - acc: 0.1926 - val_loss: 6.2805 - val_acc: 0.1565\n",
            "Epoch 8/50\n",
            "742/742 [==============================] - 32s 43ms/step - loss: 4.9591 - acc: 0.1987 - val_loss: 6.3571 - val_acc: 0.1579\n",
            "Epoch 9/50\n",
            "742/742 [==============================] - 30s 40ms/step - loss: 4.8362 - acc: 0.2034 - val_loss: 6.4447 - val_acc: 0.1568\n",
            "Epoch 10/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 4.7094 - acc: 0.2091 - val_loss: 6.5562 - val_acc: 0.1516\n",
            "Epoch 11/50\n",
            "742/742 [==============================] - 31s 42ms/step - loss: 4.5775 - acc: 0.2144 - val_loss: 6.6687 - val_acc: 0.1455\n",
            "Epoch 12/50\n",
            "742/742 [==============================] - 29s 40ms/step - loss: 4.4404 - acc: 0.2203 - val_loss: 6.7896 - val_acc: 0.1485\n",
            "Epoch 13/50\n",
            "742/742 [==============================] - 29s 38ms/step - loss: 4.2991 - acc: 0.2282 - val_loss: 6.9384 - val_acc: 0.1419\n",
            "Epoch 14/50\n",
            "742/742 [==============================] - 31s 42ms/step - loss: 4.1566 - acc: 0.2381 - val_loss: 7.0875 - val_acc: 0.1379\n",
            "Epoch 15/50\n",
            "742/742 [==============================] - 28s 38ms/step - loss: 4.0108 - acc: 0.2504 - val_loss: 7.2418 - val_acc: 0.1383\n",
            "Epoch 16/50\n",
            "742/742 [==============================] - 33s 44ms/step - loss: 3.8685 - acc: 0.2668 - val_loss: 7.3896 - val_acc: 0.1259\n",
            "Epoch 17/50\n",
            "742/742 [==============================] - 31s 41ms/step - loss: 3.7245 - acc: 0.2874 - val_loss: 7.5603 - val_acc: 0.1254\n",
            "Epoch 18/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 3.5840 - acc: 0.3067 - val_loss: 7.7211 - val_acc: 0.1153\n",
            "Epoch 19/50\n",
            "742/742 [==============================] - 31s 42ms/step - loss: 3.4476 - acc: 0.3272 - val_loss: 7.8932 - val_acc: 0.1133\n",
            "Epoch 20/50\n",
            "742/742 [==============================] - 30s 41ms/step - loss: 3.3153 - acc: 0.3469 - val_loss: 8.1050 - val_acc: 0.1050\n",
            "Epoch 21/50\n",
            "742/742 [==============================] - 30s 40ms/step - loss: 3.1891 - acc: 0.3665 - val_loss: 8.2619 - val_acc: 0.1061\n",
            "Epoch 22/50\n",
            "742/742 [==============================] - 32s 43ms/step - loss: 3.0686 - acc: 0.3857 - val_loss: 8.4252 - val_acc: 0.0964\n",
            "Epoch 23/50\n",
            "742/742 [==============================] - 30s 40ms/step - loss: 2.9508 - acc: 0.4029 - val_loss: 8.5981 - val_acc: 0.0970\n",
            "Epoch 24/50\n",
            "742/742 [==============================] - 32s 44ms/step - loss: 2.8406 - acc: 0.4242 - val_loss: 8.7872 - val_acc: 0.0945\n",
            "Epoch 25/50\n",
            "742/742 [==============================] - 30s 41ms/step - loss: 2.7349 - acc: 0.4425 - val_loss: 8.9428 - val_acc: 0.0908\n",
            "Epoch 26/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 2.6323 - acc: 0.4592 - val_loss: 9.1185 - val_acc: 0.0873\n",
            "Epoch 27/50\n",
            "742/742 [==============================] - 32s 43ms/step - loss: 2.5344 - acc: 0.4777 - val_loss: 9.2901 - val_acc: 0.0856\n",
            "Epoch 28/50\n",
            "742/742 [==============================] - 29s 40ms/step - loss: 2.4381 - acc: 0.4944 - val_loss: 9.4325 - val_acc: 0.0858\n",
            "Epoch 29/50\n",
            "742/742 [==============================] - 28s 38ms/step - loss: 2.3463 - acc: 0.5118 - val_loss: 9.6151 - val_acc: 0.0786\n",
            "Epoch 30/50\n",
            "742/742 [==============================] - 31s 42ms/step - loss: 2.2623 - acc: 0.5280 - val_loss: 9.7720 - val_acc: 0.0812\n",
            "Epoch 31/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 2.1757 - acc: 0.5449 - val_loss: 9.8992 - val_acc: 0.0761\n",
            "Epoch 32/50\n",
            "742/742 [==============================] - 32s 43ms/step - loss: 2.0941 - acc: 0.5630 - val_loss: 10.0994 - val_acc: 0.0733\n",
            "Epoch 33/50\n",
            "742/742 [==============================] - 30s 40ms/step - loss: 2.0147 - acc: 0.5769 - val_loss: 10.2420 - val_acc: 0.0707\n",
            "Epoch 34/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 1.9412 - acc: 0.5931 - val_loss: 10.3943 - val_acc: 0.0680\n",
            "Epoch 35/50\n",
            "742/742 [==============================] - 31s 42ms/step - loss: 1.8683 - acc: 0.6081 - val_loss: 10.5224 - val_acc: 0.0706\n",
            "Epoch 36/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 1.7954 - acc: 0.6247 - val_loss: 10.7066 - val_acc: 0.0675\n",
            "Epoch 37/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 1.7275 - acc: 0.6367 - val_loss: 10.8516 - val_acc: 0.0657\n",
            "Epoch 38/50\n",
            "742/742 [==============================] - 31s 42ms/step - loss: 1.6646 - acc: 0.6497 - val_loss: 10.9905 - val_acc: 0.0684\n",
            "Epoch 39/50\n",
            "742/742 [==============================] - 29s 39ms/step - loss: 1.6097 - acc: 0.6611 - val_loss: 11.1199 - val_acc: 0.0653\n",
            "Epoch 40/50\n",
            "742/742 [==============================] - 28s 38ms/step - loss: 1.5463 - acc: 0.6746 - val_loss: 11.2923 - val_acc: 0.0654\n",
            "Epoch 41/50\n",
            "742/742 [==============================] - 31s 41ms/step - loss: 1.4842 - acc: 0.6878 - val_loss: 11.4330 - val_acc: 0.0631\n",
            "Epoch 42/50\n",
            "742/742 [==============================] - 29s 40ms/step - loss: 1.4261 - acc: 0.7013 - val_loss: 11.5935 - val_acc: 0.0674\n",
            "Epoch 43/50\n",
            "742/742 [==============================] - 33s 45ms/step - loss: 1.3797 - acc: 0.7094 - val_loss: 11.7113 - val_acc: 0.0641\n",
            "Epoch 44/50\n",
            "696/742 [===========================>..] - ETA: 1s - loss: 1.3259 - acc: 0.7202"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-66da775ec729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           batch_size=64)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0madd_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_steps\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0madd_seen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLoASGFMaCPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Once the model is trained, we now have word embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yq2ZymdabjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  # How many words to generate\n",
        "  num_generate = 100\n",
        "\n",
        "  # Convert our start_string to tokens\n",
        "  input_eval = tokenizer.texts_to_sequences([start_string])\n",
        "  input_eval = tf.keras.preprocessing.sequence.pad_sequences(train_seqs,\n",
        "                                                           maxlen=50,\n",
        "                                                           dtype='int32',\n",
        "                                                           padding='pre')\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our new results\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Resetting any previous predictions\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    # Remove the batch dimension\n",
        "    prediction = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # Using categorical distribution to predict the word returned by model\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    # We pass the predicted character as the next input to the model\n",
        "    # along with the hidden state\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(tokenizer.sequences_to_texts(predicted_id)[0])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QBeM1zdctTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(generate_text(model, start_string='Othello: '))\n",
        "\n",
        "# Generates error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFM3t1kDd4Na",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d5bdc0b-1f73-47d5-a1ca-2ce3b80971d0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.argmax(model.predict([[333]]))\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrShc06VeB6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4074c6b0-91b7-4d2f-ecb6-40d39e5b6d29"
      },
      "source": [
        "tokenizer.sequences_to_texts([[333, 2]])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['same \\r']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-cqbCvDedoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Modify function to actually generate the text\n",
        "\n",
        "def generate_text(model, start_string):\n",
        "\n",
        "  # How many words to generate\n",
        "  num_generate = 100\n",
        "\n",
        "  gen_seq = []\n",
        "\n",
        "  start = tokenizer.texts_to_sequences([start_string])\n",
        "\n",
        "  for _ in range(num_generate):\n",
        "\n",
        "    pred = model.predict(start)\n",
        "    pred_word = np.argmax(pred)\n",
        "    gen_seq.append(pred_word)\n",
        "\n",
        "  print(gen_seq)\n",
        "  text = tokenizer.sequences_to_texts([gen_seq])[0]\n",
        "\n",
        "  return start_string + text"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKlElmNKfaiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5f900add-5e64-440a-e8b6-64930a61e9c4"
      },
      "source": [
        "print(generate_text(model, 'Othello \\r'))\n",
        "\n",
        "# Printing"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422, 422]\n",
            "Othello \ryours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours yours\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}