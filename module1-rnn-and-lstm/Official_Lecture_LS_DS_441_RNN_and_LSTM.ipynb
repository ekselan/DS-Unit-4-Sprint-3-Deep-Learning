{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of LS_DS_441_RNN_and_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tco8HihGpPDR",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
        "<br></br>\n",
        "<br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svwTitG1pPDR",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IizNKWLomoA"
      },
      "source": [
        "## Overview\n",
        "\n",
        "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
        "\n",
        "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
        "\n",
        "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
        "\n",
        "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# Neural Networks for Sequences (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AGpuHQmdpPDT"
      },
      "source": [
        "## Overview\n",
        "\n",
        "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
        "\n",
        "$F_n = F_{n-1} + F_{n-2}$\n",
        "\n",
        "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
        "\n",
        "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
        "\n",
        "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
        "\n",
        "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
        "\n",
        "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
        "\n",
        "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
        "\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F_Ih-Z_NpPDV"
      },
      "source": [
        "### RNN/LSTM Sentiment Classification with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ti23G0gRe3kr",
        "outputId": "fbce434f-73ef-4a87-ee4d-1ee5c297ae09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "'''\n",
        "#Trains an LSTM model on the IMDB sentiment classification task.\n",
        "The dataset is actually too small for LSTM to be of any advantage\n",
        "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
        "**Notes**\n",
        "- RNNs are tricky. Choice of batch size is important,\n",
        "choice of loss and optimizer is critical, etc.\n",
        "Some configurations won't converge.\n",
        "- LSTM loss decrease patterns during training can be quite different\n",
        "from what you see with CNNs/MLPs/etc.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1l6eAaOpPDZ",
        "colab_type": "code",
        "outputId": "0e8a606c-78e5-44f4-9765-27412f30779a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x_train[0][-81:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD68DMeDpPDc",
        "colab_type": "code",
        "outputId": "b7553e83-f85d-43e1-d510-f102a61bd434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Pad Sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb1RdSOzpPDf",
        "colab_type": "code",
        "outputId": "13ba9649-c84a-45aa-8121-4f8a50aa5dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7PI2kKZpPDi",
        "colab_type": "code",
        "outputId": "5878abc4-06ad-47e4-f679-37ba24b599cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "\"\"\"\n",
        "activation == tanh\n",
        "recurrent_activation == sigmoid\n",
        "recurrent_dropout == 0\n",
        "unroll is False\n",
        "use_bias is True\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(32, dropout=0.2, activation='tanh',\n",
        "               recurrent_constraint=\n",
        "                recurrent_dropout=0, unroll=False, use_bias=True))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 32)          640000    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 648,353\n",
            "Trainable params: 648,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYUCYK8xpPDl",
        "colab_type": "code",
        "outputId": "169cecea-522c-4c23-ef84-7bf536cfbcac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "unicorns = model.fit(x_train, y_train,\n",
        "          batch_size=1024, \n",
        "          epochs=10, \n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-554336f9f998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           validation_data=(x_test,y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:541 train_step  **\n        self.trainable_variables)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1812 _minimize\n        experimental_aggregate_gradients=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:508 apply_gradients\n        \"name\": name,\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2420 merge_call\n        return self._merge_call(merge_fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2427 _merge_call\n        return merge_fn(self._strategy, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:592 _distributed_apply  **\n        var, apply_grad_to_update_var, args=(grad,), group=False))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2013 update\n        return self._update(var, fn, args, kwargs, group)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2659 _update\n        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2665 _update_non_slot\n        result = fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:570 apply_grad_to_update_var  **\n        return var.assign(var.constraint(var))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:846 assign\n        self._shape.assert_is_compatible_with(value_tensor.shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1117 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (32, 128) and () are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Rh-0DwpPDo",
        "colab_type": "code",
        "outputId": "4bee00de-2b57-4942-e355-9cf6156d1b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(unicorns.history['loss'])\n",
        "plt.plot(unicorns.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb_36UmLpPDr",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7pETWPIe362y"
      },
      "source": [
        "# LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "enKd-skmpPDt"
      },
      "source": [
        "## Overview\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH-JkYGIpPDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF3wtjxxpPDw",
        "colab_type": "code",
        "outputId": "34eb75b5-6784-4d87-b1a5-4010a386aac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "data_files = os.listdir('./articles')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ac14733210b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./articles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './articles'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Ib5KzEEjVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/master/module1-rnn-and-lstm/wp_articles.json\"\n",
        "data = pd.read_json(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPk4mUZvErkV",
        "colab_type": "code",
        "outputId": "943d91c6-5ba8-4e63-b1da-c050a00e2452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(136, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tueAr6O_ErTS",
        "colab_type": "code",
        "outputId": "374b35c9-7467-47bc-b135-940d9e973f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>The Queens Speech is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  The Queens Speech is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQiS_zOKpPD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data['article'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvJbN9E2Fpmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGOSAlMNpPD3",
        "colab_type": "code",
        "outputId": "4f6ef031-dc60-4511-be65-377709a2581f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The threat to hard-won womens rights in Rojava is receiving little coverage in the context of Turkeys military campaign, but women there say Turkish aggression could wipe out these reforms and perhaps herald a return to the misogyny and sexual violence of militant Islamism. There is widespread concern about the possible escape of ISIS prisoners held by Kurdish forces, and on Sunday, it was reported that at least 750 people suspected of affiliation with ISIS fled a secure displacement camp in the chaos caused by Turkish shelling. In addition, several dozen high-value ISIS prisoners were reportedly left behind by U.S. troops when they retreated, the New York Times reported, and ISIS has already claimed at least two attacks in the area since the invasion started, including a car bombing that killed three people.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP0tz7MOFb6N",
        "colab_type": "code",
        "outputId": "8f61cb5a-48b4-42b6-b9ab-20f89f8c0f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KLvpfyxpPD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiWOtiiJpPD9",
        "colab_type": "code",
        "outputId": "4ea03024-1453-4246-cb19-a1c48bd078e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEunfD6opPD_",
        "colab_type": "code",
        "outputId": "7f75a4ad-d491-4ff0-ecd8-47442a3d7e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  178374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBUoa32oGw92",
        "colab_type": "code",
        "outputId": "37be3e4e-3167-4cfd-b980-ecec8d626261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Hello Griffin \\n this is a sample\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Griffin \n",
            " this is a sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9WBt8TppPEC",
        "colab_type": "code",
        "outputId": "b20d2570-ac01-44c8-ed44-6cb3aea346c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9,\n",
              " 58,\n",
              " 56,\n",
              " 6,\n",
              " 54,\n",
              " 31,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 31,\n",
              " 56,\n",
              " 78,\n",
              " 26,\n",
              " 101,\n",
              " 58,\n",
              " 39,\n",
              " 3,\n",
              " 35,\n",
              " 56,\n",
              " 31,\n",
              " 29,\n",
              " 6,\n",
              " 18,\n",
              " 18,\n",
              " 106,\n",
              " 52,\n",
              " 23,\n",
              " 26,\n",
              " 13,\n",
              " 58,\n",
              " 3,\n",
              " 29,\n",
              " 23,\n",
              " 26,\n",
              " 31,\n",
              " 29,\n",
              " 26,\n",
              " 58,\n",
              " 56,\n",
              " 26]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9VMWkY5pPEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SnWh6IspPEH",
        "colab_type": "code",
        "outputId": "612917c2-7ddb-4c23-dfd9-8d5fd75f184e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 40, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmKRn1dcH5TQ",
        "colab_type": "code",
        "outputId": "0e40592b-e084-4747-9f32-7d3041f9f2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(x[0][0])\n",
        "print(sequences[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False False False False  True False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VQxe8vUIRv5",
        "colab_type": "code",
        "outputId": "156ee05e-58ad-441f-de9e-057201a61bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "int_char[9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'C'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBwWBEpIpPEL",
        "colab_type": "code",
        "outputId": "add4b509-e656-4b5a-eca7-357fdeadcdec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRIfF6OnpPEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPvC90_VpPEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB9kfq54pPES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOSZiO0ppPEU",
        "colab_type": "code",
        "outputId": "0d9b9421-c7c2-4f1c-8043-3253ea676d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5573/5575 [============================>.] - ETA: 0s - loss: 2.5643\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"ncompromising, and kept the film from \"\n",
            "ncompromising, and kept the film from ness tte andedto F-Rsaceons B5 tare veming lares ved junt the copnory to ranusishes no sattiviss.\n",
            "\n",
            "Ans, on por wab ter tome has beots )an Cur cading,, ustedint sedadtor la cronbo, the 9ut hifk Svestimerdely A tiont of Sinwtrings stourist ated byen oul the uncs hampenviduld. at begellon ssersing tor vistion eCs on iede mowe,) Rilingalingty capr:\n",
            "\n",
            "Hepsmoovers the homnasise Sevoty Ths fores in \n",
            "5575/5575 [==============================] - 88s 16ms/step - loss: 2.5643\n",
            "Epoch 2/10\n",
            "5572/5575 [============================>.] - ETA: 0s - loss: 2.2056\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"commentator Ana Navarro-Crdenas wrote, \"\n",
            "commentator Ana Navarro-Crdenas wrote, purskels's on wor A,kys recurding a way silais, crmilfs as inloes to war sine staneled im latis stoul zrevidy Hear allo indirec. Il watcerse, a aly an extry c@uder, wolbourt aniegno-stoch reandes. you deapion as, erravyry ay a 2.\n",
            "\n",
            "Actoed Goinly his the will.\n",
            "\n",
            "Anl wave sp:ised in a Cfeing: Mas namle salld lagarus to insouus vereizenty the lagw, How hem quupal blay to dent realing of SHew0 to rotio\n",
            "5575/5575 [==============================] - 87s 16ms/step - loss: 2.2056\n",
            "Epoch 3/10\n",
            "5574/5575 [============================>.] - ETA: 0s - loss: 2.0690\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"visioned the congressmans public hangin\"\n",
            "visioned the congressmans public hanging Syw6. Otwing, for are requett saymarmente the bugefraense Wiscal. Blisving up lack contorfordey rejaces. Desiandiblay and in Stur gnily you furan cimesnatic of-22s at a pation sith the using thive Jescosain a mais watch. The jugrouserys grisesty ouccuppiat quo the farin for bo Ellakess onjs on the way hos ageaned for Buuley worlis a setuens and as they aor protin to a.r gald of a dusir Saric\n",
            "5575/5575 [==============================] - 87s 16ms/step - loss: 2.0690\n",
            "Epoch 4/10\n",
            "5574/5575 [============================>.] - ETA: 0s - loss: 1.9738\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"Subscribe and stay informed\n",
            "\n",
            "If youre v\"\n",
            "Subscribe and stay informed\n",
            "\n",
            "If youre viting from proppem. Ametonddy, senter folmen sarn feldion into ture pprsodvicioun imbled fore Hurks hat lase wituy fornerd Where said se ho way comptute in lusticlide ButhMarth. A anyout difledresced by quisons to hes Jote is deation crived. Anstediants bugned need pebluts tham thims incligd, whoone in ome imentod antoll traper: they redees, adrellon worndent fan grotwilafy and wie worcens to not\n",
            "5575/5575 [==============================] - 87s 16ms/step - loss: 1.9738\n",
            "Epoch 5/10\n",
            "5574/5575 [============================>.] - ETA: 0s - loss: 1.9007\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"to improve.\n",
            "\n",
            "If you want to improve, yo\"\n",
            "to improve.\n",
            "\n",
            "If you want to improve, you day actuake mituld ulsom. You re of lainke it cast statt, stable beed that has aguners appions wordstions. Thisceral cast on peirende beggine was that thourd array by Jussan Excurttin and oh Trumps the Yor be as that his gotobe tearly by abbo broos. Ho got becoul vastia that to sewson, and stration from gite the Hias, a svering wish of the respeanke the Unincerpeach that who wan you neen to emi\n",
            "5575/5575 [==============================] - 88s 16ms/step - loss: 1.9007\n",
            "Epoch 6/10\n",
            "4788/5575 [========================>.....] - ETA: 10s - loss: 1.8417"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTC3CCU4pPEX",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo9ePxYUpPEY",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    }
  ]
}