{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "4_3_3_L_Copy of LS_DS_433_Autoencoders_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKIlxwLLCFaT",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcSLBMVQCFaV",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoders\n",
        "\n",
        "> An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner.[1][2] The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxd_Ae9dCFaV",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "*At the end of the lecture you should be to*:\n",
        "* <a href=\"#p1\">Part 1</a>: Describe the componenets of an autoencoder\n",
        "* <a href=\"#p2\">Part 2</a>: Train an autoencoder\n",
        "* <a href=\"#p3\">Part 3</a>: Apply an autoenocder to a basic information retrieval problem\n",
        "\n",
        "__Problem:__ Is it possible to automatically represent an image as a fixed-sized vector even if it isn’t labeled?\n",
        "\n",
        "__Solution:__ Use an autoencoder\n",
        "\n",
        "Why do we need to represent an image as a fixed-sized vector do you ask? \n",
        "\n",
        "* __Information Retrieval__\n",
        "    - [Reverse Image Search](https://en.wikipedia.org/wiki/Reverse_image_search)\n",
        "    - [Recommendation Systems - Content Based Filtering](https://en.wikipedia.org/wiki/Recommender_system#Content-based_filtering)\n",
        "* __Dimensionality Reduction__\n",
        "    - [Feature Extraction](https://www.kaggle.com/c/vsb-power-line-fault-detection/discussion/78285)\n",
        "    - [Manifold Learning](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)\n",
        "\n",
        "We've already seen *representation learning* when we talked about word embedding modelings during our NLP week. Today we're going to achieve a similiar goal on images using *autoencoders*. An autoencoder is a neural network that is trained to attempt to copy its input to its output. Usually they are restricted in ways that allow them to copy only approximately. The model often learns useful properties of the data, because it is forced to prioritize which aspecs of the input should be copied. The properties of autoencoders have made them an important part of modern generative modeling approaches. Consider autoencoders a special case of feed-forward networks (the kind we've been studying); backpropagation and gradient descent still work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXColPN0CFaW",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder Architecture (Learn)\n",
        "<a id=\"p1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H932P7soCFaX",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The *encoder* compresses the input data and the *decoder* does the reverse to produce the uncompressed version of the data to create a reconstruction of the input as accurately as possible:\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png' width=800/>\n",
        "\n",
        "The learning process gis described simply as minimizing a loss function: \n",
        "$ L(x, g(f(x))) $\n",
        "\n",
        "- $L$ is a loss function penalizing $g(f(x))$ for being dissimiliar from $x$ (such as mean squared error)\n",
        "- $f$ is the encoder function\n",
        "- $g$ is the decoder function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWTd3tscCFaX",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along\n",
        "### Extremely Simple Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHZHdtH6CFaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d69d34ac-57f7-47d1-bfc3-5388a08c04e2"
      },
      "source": [
        "# Colab Only Cell\n",
        "# Remember to Switch to GPU Runtime\n",
        "%tensorflow__version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorflow__version` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fhnjV3XCFac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4qJuAK0CFaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,)) #> have 784 values in mnist\n",
        "\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# input_img is input to this encoded function\n",
        "\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation=\"sigmoid\")(encoded)\n",
        "# Using sigmoid to normalize output to be between 0 to 1\n",
        "\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX4ubL64CFai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muuiiLJPCFal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "\n",
        "# retrieve the last layer of the autoencoder model\n",
        "\n",
        "# create the decoder model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkqKJ-K9CFao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Compile\n",
        "\n",
        "autoencoder.compile(optimizer='nadam', loss='binary_crossentropy')\n",
        "# Want thr binary crossentropy of each pixel value"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQxNU4vpCFar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "85d664cb-fec5-4150-d348-81c2596bc3cb"
      },
      "source": [
        "### Load mnist data\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZUqtDlOCFat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "50d6df65-13bb-4761-c012-b5dc8ad9200a"
      },
      "source": [
        "### Normalize and reshape the data\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5GXOtp5CFaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "935d878f-16bf-4d94-ad3e-67556d5d0af1"
      },
      "source": [
        "import os\n",
        "\n",
        "# stop = EarlyStopping(monitor=..., min_delta=0.001, patience=2)\n",
        "\n",
        "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard = Tensorboard(log_dir=logdir)\n",
        "\n",
        "# Using x_train in both places because we are\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=30,\n",
        "                batch_size=64,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                verbose = True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1897 - val_loss: 0.1313\n",
            "Epoch 2/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1180 - val_loss: 0.1070\n",
            "Epoch 3/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1029 - val_loss: 0.0978\n",
            "Epoch 4/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0973 - val_loss: 0.0956\n",
            "Epoch 5/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0955 - val_loss: 0.0937\n",
            "Epoch 6/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0947 - val_loss: 0.0931\n",
            "Epoch 7/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0943 - val_loss: 0.0929\n",
            "Epoch 8/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0940 - val_loss: 0.0925\n",
            "Epoch 9/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0938 - val_loss: 0.0926\n",
            "Epoch 10/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 11/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0935 - val_loss: 0.0924\n",
            "Epoch 12/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0934 - val_loss: 0.0923\n",
            "Epoch 13/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0933 - val_loss: 0.0921\n",
            "Epoch 14/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0933 - val_loss: 0.0919\n",
            "Epoch 15/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 16/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 17/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 18/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0931 - val_loss: 0.0918\n",
            "Epoch 19/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 20/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0930 - val_loss: 0.0917\n",
            "Epoch 21/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 22/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 23/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 24/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 25/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 26/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 27/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 28/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 29/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 30/30\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0928 - val_loss: 0.0918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fae0585e470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFDA752GHKC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0a69b254-13a7-4e12-b8c3-a6d9350b364f"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 50,992\n",
            "Trainable params: 50,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpCjUVkPCFay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --log_dir='./logs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjyLFAhvCFa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "\n",
        "\n",
        "# Make predictions on test set and visualize the reconstructed vs\n",
        "# original images\n",
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNut2-nICFa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "1e83a92c-3f5a-4175-e3ce-44d4dbe88015"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "# Top row is the original\n",
        "# Bottom row is the reconstructions"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXeoMvOpIG-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the encoded / compressed predictions\n",
        "\n",
        "encoded_imgs = encoder.predict(x_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E1RouMOIM4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e031114e-0397-46e1-dc3e-b1ebdaddd950"
      },
      "source": [
        "# 32 values we compressed to represent an image\n",
        "\n",
        "encoded_imgs[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.26012182e+00, 8.87422562e+00, 5.61425018e+00, 1.07183905e+01,\n",
              "       7.48811245e+00, 3.75082588e+00, 9.91033268e+00, 7.24919081e+00,\n",
              "       1.30667095e+01, 3.68575764e+00, 2.65579009e+00, 7.04854107e+00,\n",
              "       7.39751148e+00, 4.74693441e+00, 9.66581059e+00, 8.22752380e+00,\n",
              "       3.32378149e+00, 1.09179840e+01, 3.59326601e-03, 1.32648182e+00,\n",
              "       1.03471899e+01, 5.15096092e+00, 7.86934853e+00, 7.35623598e+00,\n",
              "       1.07077579e+01, 8.46558380e+00, 8.29886627e+00, 7.59930038e+00,\n",
              "       4.25743246e+00, 4.68599701e+00, 4.37583733e+00, 2.09307384e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPDRn8Q6CFa6",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Expected to talk about the components of autoencoder and their purpose. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhFWYj71CFa6",
        "colab_type": "text"
      },
      "source": [
        "# Train an Autoencoder (Learn)\n",
        "<a id=\"p2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn121DuZCFa6",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "As long as our architecture maintains an hourglass shape, we can continue to add layers and create a deeper network. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "ApyHRqXHCFa7",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv9lmIaaCFa7",
        "colab_type": "text"
      },
      "source": [
        "### Deep Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubeGdwkvCFa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(784,))\n",
        "\n",
        "\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTY5nFWvCFbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd71dbaa-462d-4075-ef3e-f2b46fd6446d"
      },
      "source": [
        "# compile & fit model\n",
        "\n",
        "# Input and output of the data in functional api compile\n",
        "\n",
        "### LOOK INTO THIS!!!: >>> mc = ModelCheckpoint() MODEL CHECKPOINTS TO GGL DRV###\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "autoencoder.compile(loss='binary_crossentropy', optimizer='nadam')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs = 30,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))\n",
        "\n",
        "# Looking to beat .0928"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1533 - val_loss: 0.1172\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1112 - val_loss: 0.1027\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1012 - val_loss: 0.0965\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0957 - val_loss: 0.0925\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0922 - val_loss: 0.0896\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0898 - val_loss: 0.0882\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0880 - val_loss: 0.0863\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0866 - val_loss: 0.0850\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0855 - val_loss: 0.0843\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0846 - val_loss: 0.0837\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0838 - val_loss: 0.0825\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0830 - val_loss: 0.0819\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0824 - val_loss: 0.0814\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0819 - val_loss: 0.0814\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0816 - val_loss: 0.0808\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0813 - val_loss: 0.0804\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0810 - val_loss: 0.0806\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0808 - val_loss: 0.0804\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0807 - val_loss: 0.0801\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0805 - val_loss: 0.0800\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0804 - val_loss: 0.0799\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0802 - val_loss: 0.0797\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0801 - val_loss: 0.0796\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0800 - val_loss: 0.0801\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0799 - val_loss: 0.0795\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0799 - val_loss: 0.0792\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0798 - val_loss: 0.0792\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0797 - val_loss: 0.0796\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0796 - val_loss: 0.0794\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0796 - val_loss: 0.0795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fae0165a390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRRWAYhKLuoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeSjENiECFbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "f12151e2-1946-404f-ff10-1492b6259486"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "LuYkvzV3CFbE",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional autoencoder\n",
        "\n",
        "> Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
        "\n",
        "> Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmbIKXhLCFbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "# from keras.models import Model\n",
        "# from keras import backend as K\n",
        "\n",
        "# # Create Model \n",
        "\n",
        "# autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "#from keras import backend as K\n",
        "# Create Model \n",
        "input_img = Input(shape=(28,28,1))\n",
        "x = Conv2D(16,(3,3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2,2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional representation\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "autoencoder.compile(optimizer='nadam', loss='binary_crossentropy')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hszqqx8RNm_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "0afd12a2-698e-40d9-f906-b3216b044e6f"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 8)           584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 1)         145       \n",
            "=================================================================\n",
            "Total params: 4,385\n",
            "Trainable params: 4,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjP9i2q1CFbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bef96394-ed4f-4995-9403-0066fc1794bf"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z5DgG9fCFbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b717e99f-9d5a-4247-9c81-28bf7307c325"
      },
      "source": [
        "import os\n",
        "\n",
        "# stop = EarlyStopping(monitor=..., min_delta=0.001, patience=2)\n",
        "\n",
        "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard = Tensorboard(log_dir=logdir)\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=30,\n",
        "                batch_size=64,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test)\n",
        "                )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.1800 - val_loss: 0.1416\n",
            "Epoch 2/30\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.1333 - val_loss: 0.1303\n",
            "Epoch 3/30\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.1216 - val_loss: 0.1184\n",
            "Epoch 4/30\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.1149 - val_loss: 0.1110\n",
            "Epoch 5/30\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.1105 - val_loss: 0.1067\n",
            "Epoch 6/30\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.1073 - val_loss: 0.1045\n",
            "Epoch 7/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.1047 - val_loss: 0.1026\n",
            "Epoch 8/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.1027 - val_loss: 0.0998\n",
            "Epoch 9/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.1010 - val_loss: 0.0984\n",
            "Epoch 10/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0997 - val_loss: 0.0979\n",
            "Epoch 11/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0984 - val_loss: 0.0993\n",
            "Epoch 12/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0976 - val_loss: 0.0963\n",
            "Epoch 13/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0967 - val_loss: 0.0954\n",
            "Epoch 14/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0960 - val_loss: 0.0968\n",
            "Epoch 15/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0955 - val_loss: 0.0942\n",
            "Epoch 16/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0950 - val_loss: 0.0934\n",
            "Epoch 17/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0945 - val_loss: 0.0929\n",
            "Epoch 18/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0941 - val_loss: 0.0928\n",
            "Epoch 19/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0938 - val_loss: 0.0929\n",
            "Epoch 20/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0935 - val_loss: 0.0921\n",
            "Epoch 21/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0931 - val_loss: 0.0918\n",
            "Epoch 22/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0929 - val_loss: 0.0927\n",
            "Epoch 23/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0926 - val_loss: 0.0915\n",
            "Epoch 24/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0924 - val_loss: 0.0973\n",
            "Epoch 25/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0922 - val_loss: 0.0909\n",
            "Epoch 26/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0920 - val_loss: 0.0924\n",
            "Epoch 27/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0919 - val_loss: 0.0905\n",
            "Epoch 28/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0917 - val_loss: 0.0905\n",
            "Epoch 29/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0915 - val_loss: 0.0904\n",
            "Epoch 30/30\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0914 - val_loss: 0.0913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fadff025d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S95oUR0vCFbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVUfwj-qCFbO",
        "colab_type": "text"
      },
      "source": [
        "#### Visualization of the Representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2NoWevTCFbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Model(input_img, encoded)\n",
        "encoder.predict(x_train)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AyqkOBFCFbR",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will train an autoencoder at some point in the near future. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_etVbKnCFbR",
        "colab_type": "text"
      },
      "source": [
        "# Information Retrieval with Autoencoders (Learn)\n",
        "<a id=\"p3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTvQJWtCCFbS",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "A common usecase for autoencoders is for reverse image search. Let's try to draw an image and see what's most similiar in our dataset. \n",
        "\n",
        "To accomplish this we will need to slice our autoendoer in half to extract our reduced features. :) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCOQ0GSiCFbS",
        "colab_type": "text"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPnNwRyNCFbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHvbT9Q4CFbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_imgs[0].T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tSbaS8wCFbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
        "nn.fit(encoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTSYF_YCCFba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.kneighbors(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7arOWqhCFbc",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You should already be familiar with KNN and similarity queries, so the key component of this section is know what to 'slice' from your autoencoder (the encoder) to extract features from your data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AfTLa2ACFbd",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "* <a href=\"#p1\">Part 1</a>: Describe the componenets of an autoencoder\n",
        "    - Enocder\n",
        "    - Decoder\n",
        "* <a href=\"#p2\">Part 2</a>: Train an autoencoder\n",
        "    - Can do in Keras Easily\n",
        "    - Can use a variety of architectures\n",
        "    - Architectures must follow hourglass shape\n",
        "* <a href=\"#p3\">Part 3</a>: Apply an autoenocder to a basic information retrieval problem\n",
        "    - Extract just the encoder to use for various tasks\n",
        "    - AE ares good for dimensionality reduction, reverse image search, and may more things. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeCS1RyiCFbd",
        "colab_type": "text"
      },
      "source": [
        "# Sources\n",
        "\n",
        "__References__\n",
        "- [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n",
        "- [Deep Learning Cookbook](http://shop.oreilly.com/product/0636920097471.do)\n",
        "\n",
        "__Additional Material__"
      ]
    }
  ]
}